{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prophecy of ATM Withdrawals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agus Gunawan, Holy Lovenia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "from os import listdir, mkdir\n",
    "from os.path import exists, isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_from_dir_path(dir_path):\n",
    "    files = []\n",
    "    \n",
    "    for file in listdir(dir_path):\n",
    "        if file.endswith('.csv'):\n",
    "            files.append(file)\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_all_datasets(base_src_dir_path):\n",
    "\n",
    "    src_files = get_files_from_dir_path(base_src_dir_path)\n",
    "    date_parser = lambda dates: datetime.strptime(dates, '%Y-%m-%d')\n",
    "    \n",
    "    datasets = {}\n",
    "\n",
    "    for i in range(0, len(src_files)):\n",
    "        current_src_file = src_files[i]\n",
    "        current_id = current_src_file.split('.')[0]\n",
    "        current_id = current_id.split('_')[0]\n",
    "        datasets[int(current_id)] = read_csv(base_src_dir_path + current_src_file, parse_dates=['date'], date_parser=date_parser)\n",
    "        datasets[int(current_id)] = datasets[int(current_id)].rename(columns={'date': 'ds', 'Withdrawals': 'y'})\n",
    "        \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all split training datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to different natures and patterns generated by each ATM machine, the training dataset was split based on the ATM machines, e.g. K1, K2, ... ATM machine has its own dataset respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = import_all_datasets('dataset/train/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "from fbprophet.diagnostics import cross_validation, performance_metrics\n",
    "from fbprophet.plot import plot_cross_validation_metric, plot_yearly, plot_weekly\n",
    "\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Payday (holiday seasonality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the end of the month, usually the `Withdrawals` value gets higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gajian = pd.DataFrame({\n",
    "  'holiday' : 'gajian',\n",
    "  'ds' : pd.to_datetime(['2018-03-30', '2018-02-28', '2018-01-31']),\n",
    "  'lower_window' : -2,\n",
    "  'upper_window' : 2}\n",
    ")\n",
    "\n",
    "holidays = gajian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define weekly seasonality for Sunday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Sundays, `Withdrawals` is almost half of the other days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_money(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    switcher = {\n",
    "        6: 0.5\n",
    "    }\n",
    "    return switcher.get(date.weekday(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding regressor column for Sunday's `take_money` in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(train_datasets) + 1):\n",
    "    train_datasets[i]['take_money'] = train_datasets[i]['ds'].apply(take_money)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Prophet models for each dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, each model is trained using its own dataset. An additional regressor for Sunday's `take_money` (weekly seasonality) is added for every model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/holy/anaconda3/envs/nlp_text/lib/python3.6/site-packages/pystan/misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 3.0.\n",
      "/home/holy/anaconda3/envs/nlp_text/lib/python3.6/site-packages/fbprophet/forecaster.py:353: DeprecationWarning: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "  np.linspace(0, hist_size - 1, self.n_changepoints + 1)\n"
     ]
    }
   ],
   "source": [
    "prophets = {}\n",
    "\n",
    "for i in range(1, len(train_datasets) + 1):\n",
    "    prophet = Prophet(yearly_seasonality=False, \n",
    "                      weekly_seasonality=False, \n",
    "                      daily_seasonality=False, \n",
    "                      holidays=holidays)\n",
    "\n",
    "    prophet.add_regressor(name='take_money', mode='multiplicative')\n",
    "    prophet.fit(train_datasets[i])\n",
    "    \n",
    "    prophets[i] = prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting `Withdrawals`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of demonstration, let's just predict the next seven days using the first 10 ATM machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 from 10626\n"
     ]
    }
   ],
   "source": [
    "forecast_data = {}\n",
    "for i in range(1, 10 + 1):\n",
    "    if i % 10 == 0:\n",
    "        print(str(i) + ' from ' + str(len(prophets)))\n",
    "    future_data = prophets[i].make_future_dataframe(periods=7, freq='d')\n",
    "    future_data['take_money'] = future_data['ds'].apply(take_money)\n",
    "    \n",
    "    forecast_data[i] = prophets[i].predict(future_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance measure for 10 first ATM machines is computed using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get performance metrics with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fbprophet.diagnostics:Making 16 forecasts with cutoffs between 2018-01-23 12:00:00 and 2018-03-17 00:00:00\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 17.0.\n",
      "/home/holy/anaconda3/envs/nlp_text/lib/python3.6/site-packages/fbprophet/forecaster.py:353: DeprecationWarning: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "  np.linspace(0, hist_size - 1, self.n_changepoints + 1)\n",
      "/home/holy/anaconda3/envs/nlp_text/lib/python3.6/site-packages/pystan/misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 20.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 23.0.\n",
      "INFO:fbprophet.diagnostics:Making 16 forecasts with cutoffs between 2018-01-23 12:00:00 and 2018-03-17 00:00:00\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 17.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 20.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 23.0.\n",
      "INFO:fbprophet.diagnostics:Making 16 forecasts with cutoffs between 2018-01-23 12:00:00 and 2018-03-17 00:00:00\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 17.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 20.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 23.0.\n",
      "INFO:fbprophet.diagnostics:Making 16 forecasts with cutoffs between 2018-01-23 12:00:00 and 2018-03-17 00:00:00\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 17.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 20.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 23.0.\n",
      "INFO:fbprophet.diagnostics:Making 16 forecasts with cutoffs between 2018-01-23 12:00:00 and 2018-03-17 00:00:00\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 17.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 20.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 23.0.\n",
      "INFO:fbprophet.diagnostics:Making 16 forecasts with cutoffs between 2018-01-23 12:00:00 and 2018-03-17 00:00:00\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 17.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 20.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 23.0.\n",
      "INFO:fbprophet.diagnostics:Making 16 forecasts with cutoffs between 2018-01-23 12:00:00 and 2018-03-17 00:00:00\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 17.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 20.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 23.0.\n",
      "INFO:fbprophet.diagnostics:Making 16 forecasts with cutoffs between 2018-01-23 12:00:00 and 2018-03-17 00:00:00\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 17.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 20.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 23.0.\n",
      "INFO:fbprophet.diagnostics:Making 16 forecasts with cutoffs between 2018-01-23 12:00:00 and 2018-03-17 00:00:00\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 17.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 20.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 23.0.\n",
      "INFO:fbprophet.diagnostics:Making 16 forecasts with cutoffs between 2018-01-23 12:00:00 and 2018-03-17 00:00:00\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 17.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 20.0.\n",
      "INFO:fbprophet.forecaster:n_changepoints greater than number of observations.Using 23.0.\n"
     ]
    }
   ],
   "source": [
    "pm = {}\n",
    "for i in range(1, 10 + 1):\n",
    "    cv = cross_validation(prophets[i], horizon='7 days')\n",
    "    pm[i] = performance_metrics(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show averaged MSE and MAPE from each data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 mse    7.794492e+14\n",
      "dtype: float64 mape    0.184619\n",
      "dtype: float64\n",
      "2 mse    9.802238e+14\n",
      "dtype: float64 mape    0.186738\n",
      "dtype: float64\n",
      "3 mse    4.466868e+14\n",
      "dtype: float64 mape    0.217522\n",
      "dtype: float64\n",
      "4 mse    3.015438e+15\n",
      "dtype: float64 mape    0.234772\n",
      "dtype: float64\n",
      "5 mse    5.630637e+15\n",
      "dtype: float64 mape    0.23573\n",
      "dtype: float64\n",
      "6 mse    4.079609e+14\n",
      "dtype: float64 mape    0.2262\n",
      "dtype: float64\n",
      "7 mse    8.503684e+15\n",
      "dtype: float64 mape    0.253915\n",
      "dtype: float64\n",
      "8 mse    4.105107e+15\n",
      "dtype: float64 mape    0.247882\n",
      "dtype: float64\n",
      "9 mse    1.069176e+15\n",
      "dtype: float64 mape    0.410304\n",
      "dtype: float64\n",
      "10 mse    2.152590e+15\n",
      "dtype: float64 mape    0.274852\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(pm) + 1):\n",
    "    print(i, pm[i][['mse']].mean(), pm[i][['mape']].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_forecast_data = forecast_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(temp_forecast_data) + 1):\n",
    "    temp_forecast_data[i]['no. ATM'] = \"K\" + str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(temp_forecast_data) + 1):\n",
    "    temp_forecast_data[i] = temp_forecast_data[i].rename(columns={'ds': 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = {}\n",
    "\n",
    "for i in range(1, len(temp_forecast_data) + 1):\n",
    "    answer[i] = temp_forecast_data[i].loc[temp_forecast_data[i]['date'] > '2018-03-24']\n",
    "    answer[i] = answer[i][['no. ATM', 'date', 'yhat']]\n",
    "    answer[i] = answer[i].rename(columns={'yhat': 'prediction'})\n",
    "    if i % 10 == 0:\n",
    "        print(str(i) + ' from ' + str(len(temp_forecast_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat all of the answers into a single `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answer = pd.DataFrame()\n",
    "final_answer_list = []\n",
    "\n",
    "for i in range(1, len(answer) + 1):\n",
    "    final_answer_list.append(answer[i])\n",
    "        \n",
    "final_answer = pd.concat(final_answer_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save it as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answer.to_csv('result/prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
